import { NextResponse } from 'next/server';
import { HfInference } from "@huggingface/inference";

// í—ˆê¹…í˜ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const hf = new HfInference(process.env.HF_TOKEN);

export async function POST(request: Request) {
    try {
        const formData = await request.formData();
        const file = formData.get('file') as File;

        if (!file) {
            return NextResponse.json({ error: 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.' }, { status: 400 });
        }

        const arrayBuffer = await file.arrayBuffer();

        // â˜… [ìˆ˜ì • í•µì‹¬] Blobì„ ë§Œë“¤ ë•Œ 'audio/webm' ì´ë¼ê³  ë¼ë²¨ì„ ë¶™ì—¬ì¤ë‹ˆë‹¤.
        const audioData = new Blob([arrayBuffer], { type: 'audio/webm' });

        console.log("ğŸš€ Hugging Face v3-turbo ì „ì†¡ ì‹œì‘ (audio/webm)");

        const output = await hf.automaticSpeechRecognition({
            data: audioData,
            model: "openai/whisper-large-v3-turbo",
            provider: "hf-inference",
            parameters: {
                language: "ko",
                task: "transcribe" // ë²ˆì—­(translate)ì´ ì•„ë‹ˆë¼ ë°›ì•„ì“°ê¸°(transcribe)ë¥¼ í•˜ê² ë‹¤ê³  ëª…ì‹œ
            }
        });

        console.log("ğŸ“© ë³€í™˜ ê²°ê³¼:", output);

        return NextResponse.json({ text: output.text });

    } catch (error: any) {
        console.error("STT ì—ëŸ¬ ë°œìƒ:", error);

        // ë§Œì•½ 410 ì—ëŸ¬ë‚˜ 503(ë¡œë”©ì¤‘)ì´ ë‚˜ë©´ ìƒì„¸ ë‚´ìš©ì„ ì•Œ ìˆ˜ ìˆê²Œ ì¶œë ¥
        return NextResponse.json({
            error: error.message,
            detail: "ëª¨ë¸ì´ ì¤€ë¹„ ì¤‘ì´ê±°ë‚˜ ë¬´ë£Œ í‹°ì–´ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }, { status: 500 });
    }
}