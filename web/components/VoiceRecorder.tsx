'use client';

import { useState, useRef, useEffect } from 'react';

interface Props {
    // ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸(page.tsx)ì˜ í•¨ìˆ˜ì™€ ëª…ì¹­ì„ ë§ì¶¥ë‹ˆë‹¤.
    onResult: (text: string) => void;
    isProcessing: boolean;
    onStatusChange?: (status: 'recording' | 'processing' | 'idle') => void;
}

export default function VoiceRecorder({ onResult, isProcessing: parentProcessing, onStatusChange }: Props) {
    const [isRecording, setIsRecording] = useState(false);
    const [isProcessing, setIsProcessing] = useState(false);

    // ë¡œì§ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ ìƒíƒœ ì°¸ì¡°ê°’
    const isRecordingRef = useRef(false);
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const chunksRef = useRef<Blob[]>([]);

    // ë°ì‹œë²¨ ë¶„ì„ìš© Refs
    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const maxVolumeRef = useRef<number>(0);
    const animationFrameRef = useRef<number | null>(null);

    // ë‚´ë¶€ ì²˜ë¦¬ ìƒíƒœì™€ ë¶€ëª¨ ì²˜ë¦¬ ìƒíƒœë¥¼ í†µí•©
    const globalProcessing = isProcessing || parentProcessing;

    // ìƒíƒœ ë³€ê²½ ì•Œë¦¼
    useEffect(() => {
        if (onStatusChange) {
            if (globalProcessing) onStatusChange('processing');
            else if (isRecording) onStatusChange('recording');
            else onStatusChange('idle');
        }
    }, [isRecording, globalProcessing, onStatusChange]);

    // ì‹¤ì‹œê°„ ë³¼ë¥¨ ì²´í¬ (RMS ë°©ì‹)
    const monitorVolume = () => {
        if (!analyserRef.current || !isRecordingRef.current) return;

        const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
        analyserRef.current.getByteTimeDomainData(dataArray);

        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
            const amplitude = (dataArray[i] - 128) / 128;
            sum += amplitude * amplitude;
        }
        const rms = Math.sqrt(sum / dataArray.length);
        const volume = rms * 100;

        if (volume > maxVolumeRef.current) {
            maxVolumeRef.current = volume;
        }
        animationFrameRef.current = requestAnimationFrame(monitorVolume);
    };

    const startRecording = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            isRecordingRef.current = true;
            setIsRecording(true);
            chunksRef.current = [];
            maxVolumeRef.current = 0;

            const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
            const source = audioContext.createMediaStreamSource(stream);
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            source.connect(analyser);

            audioContextRef.current = audioContext;
            analyserRef.current = analyser;

            monitorVolume();

            const mimeType = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4';
            const mediaRecorder = new MediaRecorder(stream, { mimeType });
            mediaRecorderRef.current = mediaRecorder;

            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) chunksRef.current.push(e.data);
            };

            mediaRecorder.onstop = async () => {
                // ëª©ì†Œë¦¬ í¬ê¸° ì„ê³„ê°’ ì²´í¬ (10 ë¯¸ë§Œì€ ë¬´ì‹œ)
                if (maxVolumeRef.current < 10) {
                    console.log("ğŸ”Š ëª©ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•„ ì „ì†¡ì„ ì·¨ì†Œí•©ë‹ˆë‹¤.");
                    return;
                }

                setIsProcessing(true);
                try {
                    const audioBlob = new Blob(chunksRef.current, { type: mimeType });
                    const formData = new FormData();
                    formData.append('file', audioBlob, `voice.${mimeType.split('/')[1]}`);

                    // ì„œë²„ì˜ STT ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
                    const res = await fetch('/api/stt', { method: 'POST', body: formData });
                    const data = await res.json();

                    if (data.text) {
                        onResult(data.text); // ë¶€ëª¨ì—ê²Œ í…ìŠ¤íŠ¸ ì „ë‹¬
                    }
                } catch (err) {
                    console.error("STT ì „ì†¡ ì‹¤íŒ¨:", err);
                } finally {
                    setIsProcessing(false);
                }
            };

            mediaRecorder.start();
        } catch (err) {
            console.error("ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨:", err);
            alert("ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
            setIsRecording(false);
            isRecordingRef.current = false;
        }
    };

    const stopRecording = () => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
            mediaRecorderRef.current.stop();
            mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
        }
        if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
        if (audioContextRef.current) audioContextRef.current.close();

        isRecordingRef.current = false;
        setIsRecording(false);
    };

    const handleToggle = (e: React.MouseEvent | React.TouchEvent) => {
        e.stopPropagation();
        if (globalProcessing) return;

        if (isRecordingRef.current) {
            stopRecording();
        } else {
            startRecording();
        }
    };

    return (
        <div className="relative flex flex-col items-center">
            {/* ì•ˆë‚´ ë§í’ì„  */}
            {!isRecording && !globalProcessing && (
                <div className="absolute -top-14 px-4 py-2 bg-orange-500 text-white text-[12px] font-bold rounded-2xl shadow-lg whitespace-nowrap animate-bounce z-30">
                    ë§ì”€í•˜ì‹œë ¤ë©´ í„°ì¹˜í•˜ì„¸ìš”
                    <div className="absolute -bottom-1 left-1/2 -translate-x-1/2 w-3 h-3 bg-orange-500 rotate-45" />
                </div>
            )}

            {/* ë©”ì¸ ë§ˆì´í¬ ë²„íŠ¼ */}
            <button
                onClick={handleToggle}
                disabled={globalProcessing}
                className={`w-20 h-20 rounded-full flex items-center justify-center transition-all shadow-2xl relative z-20 outline-none
                    ${isRecording ? 'bg-red-500 scale-110 ring-8 ring-red-100' : 'bg-white border-4 border-orange-50'} 
                    ${globalProcessing ? 'opacity-50 cursor-not-allowed' : 'cursor-pointer active:scale-90'}`}
            >
                {/* ë…¹ìŒ ì¤‘ í¼ì§€ëŠ” íŒŒë™ íš¨ê³¼ */}
                {isRecording && (
                    <span className="absolute inline-flex h-full w-full rounded-full bg-red-400 opacity-50 animate-ping"></span>
                )}

                {globalProcessing ? (
                    <div className="w-8 h-8 border-4 border-orange-500 border-t-transparent rounded-full animate-spin" />
                ) : (
                    <span className={`text-4xl ${isRecording ? 'text-white' : 'text-orange-500'}`}>
                        {isRecording ? "â– " : "ğŸ¤"}
                    </span>
                )}
            </button>
        </div>
    );
}